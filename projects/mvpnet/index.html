<!DOCTYPE html>
<html class="msra"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>MVPNet</title>
	
	<link media="all" href="./files/style.css" type="text/css" rel="stylesheet">
</head>
<body data-gr-c-s-loaded="true">
<div id="content">
	<h1>
		MVPNet: Multi-View Point Regression Networks for 3D Object Reconstruction from A Single Image	
	</h1>
	<div id="header">
		<p id="people">
			<a href="https://www.microsoft.com/en-us/research/people/jinglwa/">Jinglu Wang<sup>1</sup></a>,
			<a href="">Bo Sun<sup>2</sup></a>,
			<a href="https://www.microsoft.com/en-us/research/people/yanlu/">Yan Lu<sup>1</sup></a>
		</p>	
		<p>

			<a><sup>1</sup>Microsoft Research Asia</a>
			<a><sup>2</sup>Peking University</a>
		</p>
		<p><em>The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19)</em></p>
	</div>
	<img id="teaser" alt="teaser" src="./files/mvp_teaser.png">
	<h2>Abstract</h2>
	<p id="text">
			In this paper, we address the problem of reconstructing an object's surface from a single image using generative networks. 
			First, we represent a 3D surface with an aggregation of dense point clouds from multiple views. Each point cloud is embedded in a regular 2D grid aligned on an image plane of a viewpoint, making the point cloud convolution-favored and ordered so as to fit into deep network architectures. The point clouds can be easily triangulated by exploiting connectivities of the 2D grids to form mesh-based surfaces. Second, we propose an encoder-decoder network that generates such kind of multiple view-dependent point clouds from a single image by regressing their 3D coordinates and visibilities.
			We also introduce a novel geometric loss that is able to interpret discrepancy over 3D surfaces as opposed to 2D projective planes, resorting to the surface discretization on the constructed meshes. 
			We demonstrate that the multi-view point regression network outperforms state-of-the-art methods with a significant improvement on challenging datasets.
	</p>
	<h2>Paper</h2>
	<table><tbody>
		<tr>
			<td>
			<a href="https://arxiv.org/abs/1811.09410">
				<img id="thumbnail" alt="paper thumbnail" src="./files/mvp_thumbnail.png">
			</a>
			</td>
			<td>
			►<a href="./files/aaai2019_svr.pdf">MVPNet.pdf</a>, 2.6 MB</a><br>
			►<a href="https://arxiv.org/abs/1811.09410">Arxiv</a><br>
			►<a href="./files/mvpnet_poster_highres.pdf">Arxiv</a><br>
			<br>
			<p>
				Jinglu Wang*, Bo Sun, Yan Lu<br>
				"MVPNet: Multi-View Point Regression Networks for 3D Object Reconstruction from A Single Image",<br>
				<em>The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19)</em>
				<!-- <a href="xxx.bib">[Bibtex]</a> -->
			</p>
			</td>
		</tr>

	</tbody></table>
	<br>
	<h2>Supplementary Material</h2>
	<p id="text">
		The following file provide additional technical details, extra analysis experiments including more qualitative results and representation analysis to the main paper.
	</p>
	<p>►<a href="./files/aaai_svr_sup_mat.pdf">Supplementary.pdf</a>, 8.2 MB</p>
	<h2>Code</h2>
	<p id="text">
		Coming soon!
	</p>
	<h2>Presentation</h2>
	<p id="text">
		Coming soon!
	</p>
	<!-- <p id="text">
		The following slides are presented in AAAI 2019 at Honolulu.
	</p> -->
	<!-- <p>►<a href="./files/MVPNet.pptx">Presentation.pptx</a>, 9.4 MB</p> -->
	<div>
	</div>
	<div id="footer"><a><img src="./files/msr_logo.jpg" alt="logo" height="40"/></a></div>
</div>


</body></html>